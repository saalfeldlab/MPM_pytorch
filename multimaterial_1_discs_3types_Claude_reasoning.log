
============================================================
=== Iteration 1 ===
============================================================
## Summary - Iteration 1/128 Complete

**Results**: R² = 0.466 (poor), slope = 0.060, training_time = 2.3min

**Diagnosis**: omega_f=80 is too high for stable SIREN training (protocol indicates >50 causes instability)

**Next iteration config change**:
- `omega_f`: 80.0 → 30.0 (within recommended 20-50 range)
- Strategy: exploit (parent=1)

Config updated and ready for iteration 2.


============================================================
=== Iteration 2 ===
============================================================
## Summary - Iteration 2 Complete

**Results:** R² = 0.529 (poor)

**Analysis:** Reducing omega_f from 80 → 30 provided only marginal improvement (+0.063 R²). The model is still severely underfitting. The key issue appears to be insufficient model capacity with hidden_dim=64.

**Next iteration (3):** 
- Parent: Node 2 (highest UCB = 1.236)
- Strategy: exploit
- Mutation: hidden_dim_nnr_f: 64 → 256
- Rationale: Increasing capacity should improve R², keeping omega_f=30 constant to isolate the effect of capacity


============================================================
=== Iteration 3 ===
============================================================
## Iteration 3 Summary

**Results:** R²=0.833 (moderate), slope=0.224, training_time=6.6min

**Key finding:** Increasing hidden_dim 64→256 gave a major R² improvement (+0.304), confirming model capacity was the limiting factor. The poor slope (0.224 vs target ~1.0) suggests systematic prediction bias that may improve with more capacity.

**UCB Selection:** Node 3 has highest UCB=1.699

**Strategy:** exploit — continue capacity increase

**Mutation for Iter 4:** hidden_dim_nnr_f: 256→512

Config updated and ready for iteration 4.


============================================================
=== Iteration 4 ===
============================================================
**Iteration 4 Summary:**

| Metric | Value |
|--------|-------|
| R² | 0.832 (moderate) |
| Slope | 0.359 |
| Training time | 19.3 min |
| hidden_dim | 512 |

**Key Finding:** Capacity plateau confirmed — doubling hidden_dim from 256→512 gave zero R² improvement while tripling training time (6.6→19.3 min). The persistent low slope (~0.36) suggests the bottleneck is not model capacity but possibly learning rate or optimization dynamics.

**Next Iteration (5):**
- Parent: Node 3 (hidden_dim=256, better time efficiency)
- Mutation: lr_NNR_f: 1E-5 → 5E-5
- Rationale: Higher learning rate may allow model to escape systematic bias causing low slope


============================================================
=== Iteration 5 ===
============================================================
**Iteration 5 Complete - Summary:**

**Results**: Excellent breakthrough! R²=0.953, slope=0.730, training_time=6.3min
- lr_NNR_f increase from 1E-5 to 5E-5 gave major improvement
- R²: 0.833 → 0.953 (+0.120)
- Slope: 0.224 → 0.730 (+0.506)

**Key Insight**: Learning rate was the bottleneck, not model capacity. hidden_dim=256 is sufficient when lr is appropriate.

**Next Iteration (6)**: 
- Parent: Node 5 (highest UCB=2.071)
- Strategy: exploit - continue lr exploration
- Mutation: lr_NNR_f 5E-5 → 1E-4 
- Goal: Push slope closer to 1.0 while maintaining R² > 0.95

**Config for Iter 6**:
- lr_NNR_f=1E-4
- hidden_dim_nnr_f=256
- omega_f=30.0
- n_layers_nnr_f=3
- batch_size=1
- total_steps=50000


============================================================
=== Iteration 6 ===
============================================================
## Iteration 6 Summary

**Results**: R²=0.728 (moderate), slope=0.609, training_time=6.3min
- lr_NNR_f=1E-4 was too high and caused significant regression from the excellent Iter 5 results (R² 0.953→0.728)
- Established upper bound: lr_NNR_f should not exceed 5E-5 for siren_txy on Jp field

**Key Findings**:
- lr_NNR_f=5E-5 confirmed as optimal (Iter 5 breakthrough)
- lr_NNR_f=1E-4 causes training instability (Iter 6 failure)

**Config for Iteration 7**:
- **Parent**: Node 5 (best R²=0.953)
- **Strategy**: exploit with switch-param (lr already explored, try depth)
- **Mutation**: n_layers_nnr_f: 3→4 (try increased depth to improve slope toward 1.0)
- **Config**: lr_NNR_f=5E-5, hidden_dim=256, n_layers=4, omega_f=30.0


============================================================
=== Iteration 7 ===
============================================================
## Iteration 7 Summary

**Results:** R²=0.920 (good), slope=0.696, training_time=8.1min

**Analysis:** Adding a 4th layer (n_layers 3→4) degraded performance compared to Node 5:
- R²: 0.953 → 0.920 (-0.033)
- slope: 0.730 → 0.696 (-0.034)
- Training time: 6.3 → 8.1min (+28%)

This confirms n_layers=3 is optimal. More depth doesn't help and may cause overfitting or optimization difficulties.

**Config for Iteration 8:**
- Branching back to Node 5 config (best: R²=0.953)
- Mutation: omega_f 30→20
- Rationale: Explored lr (optimal=5E-5), hidden_dim (optimal=256), n_layers (optimal=3). Now testing if lower frequency helps slope reach closer to 1.0

**Current best config:** lr_NNR_f=5E-5, hidden_dim=256, omega_f=30, n_layers=3 → R²=0.953, slope=0.730


============================================================
=== Iteration 8 ===
============================================================
**Iteration 8 Complete**

## Summary

**Iteration 8 Results (omega_f 30→20):**
- R² = 0.931 (good, but regressed from 0.953)
- slope = 0.665 (regressed from 0.730)
- Training time: 6.3 min

**Key Finding:** Lower omega_f (20) hurt performance compared to omega_f=30. This establishes a lower bound: omega_f should not go below 30 for siren_txy on Jp field.

**Current Best Configuration (Node 5):**
- lr_NNR_f=5E-5, hidden_dim=256, omega_f=30, n_layers=3
- R²=0.953, slope=0.730, 6.3min training

**Block 1 Pattern (8 iterations):**
- All mutations from Node 5 (lr increase, depth, omega_f decrease) have failed to improve
- Node 5 remains the optimal configuration
- Slope=0.730 is plateaued; may need fundamentally different approach

**Next Iteration (9):**
- Parent: Node 5 (highest performer)
- Mutation: omega_f 30→40 (try higher frequency)
- Rationale: Lower omega_f hurt; higher omega_f might help slope approach 1.0

